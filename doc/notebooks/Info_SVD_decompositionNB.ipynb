{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD Decomposition    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyJvsip as pjv\n",
    "f='%.5f'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve using SVD Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some data `A x = b`   \n",
    "Here we create matrix view `A` and vector view `x` with random data and calculate vector view `b` directly using a matrix product. To demonstrate we work backward and use `A` and `b` to estimate `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A\n",
      "[ 0.50802  0.53515  0.69864 -0.96027  0.23142;\n",
      "  0.04042 -0.47661  0.20765  0.50621 -0.38285;\n",
      "  0.15746  0.78115 -0.96815 -0.32034  0.79250;\n",
      "  0.79172 -0.25782  0.12663  1.35454  0.25523;\n",
      " -0.19460  0.34111 -0.49602  0.17191  1.62412]\n",
      "\n",
      "Known x vector\n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "Calculated b=Ax vector\n",
      "[-2.02196  1.48038 -1.66977  2.12221 -1.26404]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n=5\n",
    "A=pjv.create('mview_d',n,n).fill(0.0)\n",
    "A.randn(5)\n",
    "x=pjv.create('vview_d',n).randn(9)\n",
    "print('Matrix A');A.mprint(f)\n",
    "print('Known x vector');x.mprint(f)\n",
    "b=A.prod(x)\n",
    "print('Calculated b=Ax vector');b.mprint(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both LU and SV overwrite the input matrix; so to preserve our original matrix we use a copy. The LU (and SV) object will keep a reference to the copy (which means python will not garbage collect it). We solve this first using SVD. We don't overwrite our original vector so we can compare the estimated solution to the actual solution. SVD does not have a solver so we do it long hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.16633 -0.51229  0.81948  0.05967  0.18652;\n",
      "  0.31930  0.19799 -0.02838  0.10168  0.92071;\n",
      " -0.62185  0.03518 -0.11646 -0.71963  0.28397;\n",
      "  0.16958  0.74590  0.55949 -0.26861 -0.17230;\n",
      " -0.67448  0.37516  0.03252  0.62935  0.08474]\n",
      "\n",
      "[ 0.04232  0.14322  0.71005 -0.55408  0.40808;\n",
      " -0.44110 -0.21437  0.19419 -0.39443 -0.75246;\n",
      "  0.40030 -0.23400  0.62540  0.55313 -0.29654;\n",
      "  0.27958  0.87559 -0.00045 -0.04143 -0.39174;\n",
      " -0.75182  0.33485  0.25885  0.47933  0.16087]\n",
      "\n",
      "[ 2.26877  1.89101  1.17381  0.74723  0.05827]\n",
      "\n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "Forbenius norm of x estimate - x is 1.54231e-14\n"
     ]
    }
   ],
   "source": [
    "u,s,v=A.copy.svd\n",
    "u.mprint(f)\n",
    "v.mprint(f)\n",
    "s.mprint(f)\n",
    "# check for zeros in s\n",
    "assert s.leq(0.0).sumval == 0,'There is at least one zero singular value so no solution'\n",
    "# only works in python2\n",
    "# xe=v.prod(u.transview.prod(b)/s)\n",
    "t=u.transview.prod(b)\n",
    "xe=v.prod(pjv.div(t,s,t))\n",
    "x.mprint(f)\n",
    "xe.mprint(f)\n",
    "print('Forbenius norm of x estimate - x is %.5e'%(xe-x).normFro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we solve using LU. We start with the LU class directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many class instance variables have a type selector (tSel) which is a dictionary which lets you select the decomposition type using the matrix type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example of LU.tSel: lu_d\n",
      "Solve for x using b. Done in place. Here we make a copy of b first. \n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "Forbenius norm of x estimate - x is 1.83544e-15\n"
     ]
    }
   ],
   "source": [
    "print('Example of LU.tSel: %s'%pjv.LU.tSel[A.type])\n",
    "luObj = pjv.LU(pjv.LU.tSel[A.type],n)\n",
    "_=luObj.lud(A.copy)\n",
    "print('Solve for x using b. Done in place. Here we make a copy of b first. ')\n",
    "xe = b.copy\n",
    "luObj.solve(pjv.VSIP_MAT_NTRANS,xe).mprint(f)\n",
    "print('Forbenius norm of x estimate - x is %.5e'%(xe-x).normFro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we solve using the SV Class directly without using a pyJvsip convenience method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Matrix\n",
      "[ 0.508  0.535  0.699 -0.960  0.231;\n",
      "  0.040 -0.477  0.208  0.506 -0.383;\n",
      "  0.157  0.781 -0.968 -0.320  0.793;\n",
      "  0.792 -0.258  0.127  1.355  0.255;\n",
      " -0.195  0.341 -0.496  0.172  1.624]\n",
      "\n",
      "Input b values\n",
      "[-2.0220  1.4804 -1.6698  2.1222 -1.2640]\n",
      "\n",
      "Singular Values\n",
      "[ 2.2688  1.8910  1.1738  0.7472  0.0583]\n",
      "\n",
      "x\n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "x estimate\n",
      "[ 0.39248 -1.35556 -0.24268  1.22453 -0.65029]\n",
      "\n",
      "Forbenius norm of x estimate - x is 1.54231e-14\n"
     ]
    }
   ],
   "source": [
    "svObj = pjv.SV(pjv.SV.tSel[A.type],A.collength,A.rowlength,'FULL','FULL')\n",
    "print('Input Matrix'); A.mprint('%.3f')\n",
    "print('Input b values');b.mprint('%.4f')\n",
    "m=A.collength; n=A.rowlength\n",
    "if m > n:\n",
    "    s=A.rowview(0).empty.fill(0.0)\n",
    "else:\n",
    "    s=A.colview(0).empty.fill(0.0)\n",
    "svObj.svd(A.copy,s)\n",
    "print('Singular Values');s.mprint('%.4f')\n",
    "V=pjv.create(A.type,n,n); U=pjv.create(A.type,m,m)\n",
    "svObj.matV(0,n,V)\n",
    "svObj.matU(0,m,U)\n",
    "#xe=V.prod(U.transview.prod(b)/s)\n",
    "t=U.transview.prod(b)\n",
    "xe=V.prod(pjv.div(t,s,t))\n",
    "print('x');x.mprint(f)\n",
    "print('x estimate');xe.mprint(f)\n",
    "print('Forbenius norm of x estimate - x is %.5e'%(xe-x).normFro)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
